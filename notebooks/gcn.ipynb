{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph convolutional networks\n",
    "\n",
    "Resources:\n",
    "\n",
    "- https://towardsdatascience.com/how-to-do-deep-learning-on-graphs-with-graph-convolutional-networks-7d2250723780\n",
    "- https://github.com/tkipf/pygcn\n",
    "- http://tkipf.github.io/graph-convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from networkx import karate_club_graph, to_numpy_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "zkc = karate_club_graph()\n",
    "order = sorted(list(zkc.nodes()))\n",
    "labels = [zkc.nodes[i][\"club\"] for i in order]\n",
    "labels = LabelBinarizer().fit_transform(y=labels)\n",
    "labels = labels.reshape(-1)\n",
    "\n",
    "# Build the adjency matrix A\n",
    "A = to_numpy_matrix(zkc, nodelist=order)  # 34x34 shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(mx):\n",
    "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
    "    rowsum = np.array(mx.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    mx = r_mat_inv.dot(mx)\n",
    "    \n",
    "    return mx\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum()\n",
    "    \n",
    "    return correct / len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(Module):\n",
    "    \"\"\"\n",
    "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, X, adj):\n",
    "        support = torch.mm(X, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            output = output + self.bias\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"{0} ({1} -> {2})\".format(self.__class__.__name__,\n",
    "                                         self.in_features,\n",
    "                                         self.out_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, nfeat, nhid, nclass, dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
    "        self.gc2 = GraphConvolution(nhid, nclass)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        x = self.gc2(x, adj)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add identity matrix --> A_hat\n",
    "assert np.allclose(np.asarray(A.diagonal()), np.zeros(A.shape[0]))\n",
    "A_hat = A + sp.eye(A.shape[0])\n",
    "assert np.allclose(np.asarray(A_hat.diagonal()), np.ones(A_hat.shape[0]))\n",
    "\n",
    "# Normalize A_hat\n",
    "A_hat_norm = normalize(A_hat)\n",
    "assert A_hat_norm.shape == A.shape\n",
    "assert np.allclose(np.asarray(A_hat_norm.sum(axis=1)), np.ones((A.shape[0], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we have no features, use the identity matrix\n",
    "features = np.eye(A.shape[0])\n",
    "features = normalize(features)  # useless for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels\n",
    "labels = torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to torch tensor\n",
    "A_hat_norm = torch.FloatTensor(np.asarray(A_hat_norm))\n",
    "features = torch.FloatTensor(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 loss_train: 0.7618 acc_train: 0.5000\n",
      "Epoch: 0002 loss_train: 0.7331 acc_train: 0.5000\n",
      "Epoch: 0003 loss_train: 0.7069 acc_train: 0.5000\n",
      "Epoch: 0004 loss_train: 0.6949 acc_train: 0.5000\n",
      "Epoch: 0005 loss_train: 0.6782 acc_train: 0.5000\n",
      "Epoch: 0006 loss_train: 0.6620 acc_train: 0.5000\n",
      "Epoch: 0007 loss_train: 0.6437 acc_train: 0.5000\n",
      "Epoch: 0008 loss_train: 0.6361 acc_train: 0.5000\n",
      "Epoch: 0009 loss_train: 0.6239 acc_train: 0.6765\n",
      "Epoch: 0010 loss_train: 0.5865 acc_train: 0.8824\n",
      "Epoch: 0011 loss_train: 0.5548 acc_train: 0.9412\n",
      "Epoch: 0012 loss_train: 0.5333 acc_train: 0.9118\n",
      "Epoch: 0013 loss_train: 0.5022 acc_train: 0.9706\n",
      "Epoch: 0014 loss_train: 0.5458 acc_train: 0.9412\n",
      "Epoch: 0015 loss_train: 0.4635 acc_train: 0.9412\n"
     ]
    }
   ],
   "source": [
    "model = GCN(nfeat=features.shape[1],\n",
    "            nhid=4,\n",
    "            nclass=2,\n",
    "            dropout=.3)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(),\n",
    "                       lr=.05,\n",
    "                       weight_decay=.01)\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(features, A_hat_norm)\n",
    "\n",
    "    loss_train = F.nll_loss(output, labels)\n",
    "    acc_train = accuracy(output, labels)\n",
    "    loss_train.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch: {:04d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()))\n",
    "\n",
    "for i in range(15):\n",
    "    train(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
