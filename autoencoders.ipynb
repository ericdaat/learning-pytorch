{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder in Pytorch\n",
    "\n",
    "From https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super().__init__()\n",
    "        self.encoder_hidden_layer = nn.Linear(\n",
    "            in_features=input_shape, out_features=128\n",
    "        )\n",
    "        self.encoder_output_layer = nn.Linear(\n",
    "            in_features=128, out_features=128\n",
    "        )\n",
    "        self.decoder_hidden_layer = nn.Linear(\n",
    "            in_features=128, out_features=128\n",
    "        )\n",
    "        self.decoder_output_layer = nn.Linear(\n",
    "            in_features=128, out_features=input_shape\n",
    "        )\n",
    "\n",
    "    def forward(self, features):\n",
    "        activation = self.encoder_hidden_layer(features)\n",
    "        activation = torch.relu(activation)\n",
    "        code = self.encoder_output_layer(activation)\n",
    "        code = torch.relu(code)\n",
    "        activation = self.decoder_hidden_layer(code)\n",
    "        activation = torch.relu(activation)\n",
    "        activation = self.decoder_output_layer(activation)\n",
    "        reconstructed = torch.relu(activation)\n",
    "        \n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create a model from `AE` autoencoder class\n",
    "# load it to the specified device, either gpu or cpu\n",
    "model = AE(input_shape=784).to(device)\n",
    "\n",
    "# create an optimizer object\n",
    "# Adam optimizer with learning rate 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# mean-squared error loss\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./torch_datasets/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0a5178241643afb46434795f96b0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./torch_datasets/MNIST/raw/train-images-idx3-ubyte.gz to ./torch_datasets/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./torch_datasets/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f5bb3f23a448b69112eeab338d722b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./torch_datasets/MNIST/raw/train-labels-idx1-ubyte.gz to ./torch_datasets/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./torch_datasets/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcecf24351947459fb288b409254eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./torch_datasets/MNIST/raw/t10k-images-idx3-ubyte.gz to ./torch_datasets/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./torch_datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9684a28fd58447c48acd791a1f9f7a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./torch_datasets/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./torch_datasets/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./torch_datasets\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./torch_datasets\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False, num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1/10, loss = 0.031913\n",
      "epoch : 2/10, loss = 0.017045\n",
      "epoch : 3/10, loss = 0.015064\n",
      "epoch : 4/10, loss = 0.014032\n",
      "epoch : 5/10, loss = 0.013339\n",
      "epoch : 6/10, loss = 0.012835\n",
      "epoch : 7/10, loss = 0.012474\n",
      "epoch : 8/10, loss = 0.012191\n",
      "epoch : 9/10, loss = 0.011971\n",
      "epoch : 10/10, loss = 0.011781\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for batch_features, _ in train_loader:\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        batch_features = batch_features.view(-1, 784).to(device)\n",
    "        \n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute reconstructions\n",
    "        outputs = model(batch_features)\n",
    "        \n",
    "        # compute training reconstruction loss\n",
    "        train_loss = criterion(outputs, batch_features)\n",
    "        \n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_features, _ in test_loader:\n",
    "    batch_features = batch_features.view(-1, 784).to(device)\n",
    "    \n",
    "    outputs = model(batch_features)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "# original\n",
    "axs[0].imshow(\n",
    "    batch_features[0].data.view(28, 28),\n",
    "    aspect=\"equal\"\n",
    ")\n",
    "axs[0].set_title(\"Original\")\n",
    "axs[0].axis('off')\n",
    "\n",
    "# reconstruction\n",
    "axs[1].imshow(\n",
    "    outputs[0].data.view(28, 28),\n",
    "    aspect=\"equal\"\n",
    ")\n",
    "axs[1].set_title(\"Reconstruction\")\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.suptitle(\"AE MNIST reconstruction\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
